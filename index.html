<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Geometrically-grounded implicit representations of 3D+time cardiac function from 2D short- and long-axis MR views">
  <meta name="keywords" content="NISF, CMR, segmentation">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>NISF++: Neural Implicit Segmentation Functions for cardiac MR </title>

<link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <style>
    /* Consolidated mesh gallery styles */
    .mesh-gallery-section {
        padding: 40px 20px;
    }

    .mesh-gallery {
        display: flex;
        gap: 20px;
        justify-content: center;
        flex-wrap: wrap;
        max-width: 1200px;
        margin: 0 auto;
    }

    .mesh-item {
        display: flex;
        flex-direction: column;
        flex: 1;
        min-width: 300px;
        max-width: 600px;
    }

    .mesh-container {
        width: 100%;
        height: 400px;
        border: 1px solid #ddd;
        border-radius: 8px;
        overflow: hidden;
        box-shadow: 0 2px 8px rgba(0,0,0,0.1);
        display: flex;
        align-items: center;
        justify-content: center;
        background-color: #000;
    }

    .mesh-container iframe {
        width: 100%;
        height: 100%;
        border: none;
    }

    .mesh-container video {
        width: 100%;
        height: 100%;
        object-fit: contain;
        display: block;
    }

    .mesh-label {
        text-align: center;
        margin-top: 10px;
        font-weight: bold;
        color: #333;
        line-height: 1.4;
    }

    .interactive-label {
        text-align: left;
        font-size: 12px;
        color: #666;
        font-style: italic;
        margin-bottom: 5px;
        min-height: 18px;
    }

    .section-subtitle {
        text-align: center;
        margin: 30px auto;
        max-width: 900px;
        line-height: 1.6;
        color: #333;
        padding: 0 20px;
    }

    @media (max-width: 768px) {
        .mesh-item {
            min-width: 100%;
        }

        .mesh-container {
            height: 300px;
        }
    }
  </style>
</head>
<body>
<!--<nav class="navbar" role="navigation" aria-label="main navigation">-->
<!--  <div class="navbar-brand">-->
<!--    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">-->
<!--      <span aria-hidden="true"></span>-->
<!--      <span aria-hidden="true"></span>-->
<!--      <span aria-hidden="true"></span>-->
<!--    </a>-->
<!--  </div>-->
<!--  <div class="navbar-menu">-->
<!--    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">-->
<!--      <a class="navbar-item" href="https://keunhong.com">-->
<!--      <span class="icon">-->
<!--          <i class="fas fa-home"></i>-->
<!--      </span>-->
<!--      </a>-->

<!--      <div class="navbar-item has-dropdown is-hoverable">-->
<!--        <a class="navbar-link">-->
<!--          More Research-->
<!--        </a>-->
<!--        <div class="navbar-dropdown">-->
<!--          <a class="navbar-item" href="https://hypernerf.github.io">-->
<!--            HyperNeRF-->
<!--          </a>-->
<!--          <a class="navbar-item" href="https://nerfies.github.io">-->
<!--            Nerfies-->
<!--          </a>-->
<!--          <a class="navbar-item" href="https://latentfusion.github.io">-->
<!--            LatentFusion-->
<!--          </a>-->
<!--          <a class="navbar-item" href="https://photoshape.github.io">-->
<!--            PhotoShape-->
<!--          </a>-->
<!--        </div>-->
<!--      </div>-->
<!--    </div>-->

<!--  </div>-->
<!--</nav>-->


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">NISF++: Neural Implicit Segmentation Functions for cardiac MR</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=bGXBGNEAAAAJ&hl=en&oi=sra">Nil Stolt-Ansó</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=wulrw9kAAAAJ&hl=en&oi=sra">Maik Dannecker</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=UjcJew4AAAAJ&hl=en&oi=sra">Steven Jia</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=hy6MSk4AAAAJ&hl=en&oi=sra">Julian McGinnis</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?hl=en&user=H0O0WnQAAAAJ">Daniel Rueckert</a><sup>1,3</sup>,
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Technical University of Munich,</span>
            <span class="author-block"><sup>2</sup>Aix-Marseille Université</span>
            <span class="author-block"><sup>3</sup>Imperial College London</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <span class="link-block">
                <a href="#" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon"><i class="fas fa-file-pdf"></i></span>
                  <span>Paper (Pending)</span>
                </a>
              </span>
              <span class="link-block">
                <a href="#" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon"><i class="ai ai-arxiv"></i></span>
                  <span>arXiv (Pending)</span>
                </a>
              </span>
              <span class="link-block">
                <a href="#" class="external-link button is-normal is-rounded is-dark" aria-disabled="true" tabindex="-1">
                  <span class="icon"><i class="fab fa-youtube"></i></span>
                  <span>Video (Pending)</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://github.com/NILOIDE/CMR_representations" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon"><i class="fab fa-github"></i></span>
                  <span>Code</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://www.ukbiobank.ac.uk/use-our-data/apply-for-access/" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon"><i class="far fa-images"></i></span>
                  <span>Data</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <h2 class="subtitle has-text-centered">
        <span class="dnerf">NISF++</span> takes any number of cardiac short-axis and long-axis MR slices and combines them into continuous 4D subject representations in world-space.
      </h2>
      <img src="./static/images/Main_fig-Page-1.jpg" class="interpolation-image" alt="Architectural figure."/>
    </div>
  </div>
</section>


<!-- Section 1: High-resolution volumes -->
<section class="mesh-gallery-section">
  <div class="container">
    <h2 class="section-subtitle">
      High-resolution intensity volumes and ventricle segmentations can be generated for any time point in the cardiac phase.
    </h2>
    <div class="mesh-gallery">
      <div class="mesh-item">
        <div class="interactive-label"></div>
        <div class="mesh-container">
          <video id="1037010_vol" autoplay controls muted loop playsinline>
            <source src="./static/videos/20251217-035047-inference_trainSet_FT_ImageVisualization_test_opt5000_ft0250_volumes_1037287_highThresh110_planeNorm(0.2, 1.0, -0.15)_offset-40_cardiac_volume.mp4" type="video/mp4">
          </video>
        </div>
        <div class="mesh-label">Intensity volume can be interpolated to any desired resolution <br> (Blood pools made transparent for visualization purposes)</div>
      </div>

      <div class="mesh-item">
        <div class="interactive-label"></div>
        <div class="mesh-container">
          <video id="1021869_mesh" autoplay controls muted loop playsinline>
            <source src="./static/videos/20251125-034718-psf20k_100subj-20ann_1011525.mp4" type="video/mp4">
          </video>
        </div>
        <div class="mesh-label">Meshes can be generated from <br> super-resolution segmentation predictions</div>
      </div>
    </div>
  </div>
</section>


<!-- Section 2: Mutually consistent segmentations -->
<section class="mesh-gallery-section">
  <div class="container">
    <h2 class="section-subtitle">
      By design, the segmentation on every slice are precisely mutually consistent, as they are 2D cross-sectional slices of the same 3D representation.<br>
      This is something conventional slice-wise segmentation methods are not able to guarantee.
    </h2>
    <div class="mesh-gallery">
      <div class="mesh-item">
        <div class="interactive-label"></div>
        <div class="mesh-container">
          <video id="mosaic_video" autoplay controls muted loop playsinline>
            <source src="./static/videos/20251125-034718-psf20k_100subj-20ann_1021869_mosaic.mp4" type="video/mp4">
          </video>
        </div>
        <div class="mesh-label">Segmenting a slice equates to <br> taking 2D cross-section of 3D representation</div>
      </div>

      <div class="mesh-item">
        <div class="interactive-label">(Interactive demo)</div>
        <div class="mesh-container">
          <iframe src="./static/objs/20251125-034718-psf20k_100subj-20ann_1021869_pred_slices_after.html"></iframe>
        </div>
        <div class="mesh-label">Segmentations across all slices <br> are precisely mutually consistent</div>
      </div>
    </div>
  </div>
</section>

<!-- Section 3: Motion correction -->
<section class="mesh-gallery-section">
  <div class="container">
    <h2 class="section-subtitle">
      The optimization process corrects for commonplace respiratory and patient motion by refining rigid parameters in the world-space transformation.<br>
      We show how the prior to optimization slices often contain severe misalignment. Meanwhile, post-optimization overlap of intensities and segmentation along slice intersections is minimized.
    </h2>
    <div class="mesh-gallery">
      <div class="mesh-item">
        <div class="interactive-label">(Interactive demo)</div>
        <div class="mesh-container">
          <iframe src="./static/objs/1021869_before.html"></iframe>
        </div>
        <div class="mesh-label">Initial alignment of GT segmentations <br>(notice misalignments between long- and short-axis slices)</div>
      </div>

      <div class="mesh-item">
        <div class="interactive-label">(Interactive demo)</div>
        <div class="mesh-container">
          <iframe src="./static/objs/1021869_after.html"></iframe>
        </div>
        <div class="mesh-label">Optimized alignment of GT segmentations</div>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Clinical acquisition in cardiac magnetic resonance (CMR) imaging involves obtaining cross-sectional planes of the heart along the radial and longitudinal directions.
Despite these planes being 2D cross-sectional images of the heart, radiologists understand the 3D spatial and continuous temporal nature of the organ being imaged.
The same can not be said about the conventional deep learning architectures used to process CMR images, which rely on in-plane and grid-based operations and are hence unable to integrate all imaging planes.
          </p>
          <p>
            In this paper, we build upon previous work on neural implicit segmentation functions (NISF) to overcome unaddressed challenges in cardiac function modeling in the CMR domain.
For a given subject, our architecture builds a shared 3D+time representations from all available acquisition planes regardless of orientation.
By design, predictions along any imaging plane orientation are cross-sections of the overall 3D representation, leading to spatio-temporal consistency across all slices.
Moreover, our architecture makes the rotation and translation parameters of imaging planes learnable, allowing us to correct for the commonplace respiratory and patient motion between slice acquisitions under a rigid assumption.
Furthermore, interpolation of intensities and segmentation can be performed in 4D at any desired resolution.
          </p>
          <p>
            We perform our study on a 120 subject sub-cohort of CMR imaging data from the UK-Biobank.
We show our in-plane segmentation performance to be on-par with existing CMR segmentation methods and explore how the majority of failure cases arise from limitations in the ground-truth segmentation, for which our representations make predictions with better anatomical accuracy than its original training data.
We also evaluate our motion-correction capabilities, displaying quantitative and qualitative improvements in slice alignment.
Our qualitative results explore how our representations can be derived irrespective of missing acquisition planes and opens up avenues towards modeling complex sub-structures such as papillary muscles.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Related Links</h2>
        <div class="content has-text-justified">
          <p>
            There's a lot of excellent work that was introduced around the same time as ours.
          </p>
          <p>
            <a href="https://arxiv.org/abs/2510.04021">Fit Pixels, Get Labels (Vyas, et al. 2025)</a> meta-learns weight initializations for implicit networks which can then be fine-tuned on images to provide segmentations.
          </p>
          <p>
            <a href="https://papers.miccai.org/miccai-2025/0638-Paper4418.html">NIMOSEF (Banus, et al. 2025)</a> Extends the original NISF paper to also model spatial deformations.
          </p>
          <p>
            <a href="https://arxiv.org/abs/2506.09668">CINeMA (Dannecker, et al. 2025)</a> Generates conditional implicit spatio-semporal atlases of the perinatal brain.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX (Pending)</h2>
    <pre><code>@misc{stolt2026nisf
  author    = {Stolt-Ansó, Nil and Dannecker, Maik and Jia, Steven and McGinnis, Julian and Rueckert, Daniel},
  title     = {NISF++: Geometrically-grounded implicit representations of 3D+time cardiac function from 2D short- and long-axis MR views},
  journal   = {ArXiv},
  year      = {2026},
}
</code></pre>
  </div>
</section>

<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
<!--      <a class="icon-link" href="./static/videos/nerfies_paper.pdf">-->
<!--        <i class="fas fa-file-pdf"></i>-->
<!--      </a>-->
      <a class="icon-link" href="https://github.com/NILOIDE" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This project page is forked from the <a href="https://github.com/nerfies/nerfies.github.io">Nerfies (Park, et al.)</a> template.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>